{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Preference Data Generation Using Meta's Llama 3.1 405B Instruct\n",
    "\n",
    "The following notebook will demonstrate how to leverage [Meta's Llama 3.1 405B Instruct](https://build.nvidia.com/meta/llama3.1-405b-instruct), and [Nemotron-4 340B Reward](https://build.nvidia.com/nvidia/nemotron-4-340b-reward) through [build.nvidia.com](https://build.nvidia.com/explore/discover).\n",
    "\n",
    "The build will be a demonstration of the following pipeline.\n",
    "\n",
    "![image](./SDG%20Pipeline.png)\n",
    "\n",
    "The flow will be split into 2 general parts: \n",
    "\n",
    "1. **Synthetic Response Generation**: A domain specific input query will be provided by the developer - at which point Llama 3.1 405B Instruct will be leveraged to generate ~150 questions. Then, Llama 3.1 405B Instruct will be used to generated 2 responses for each question. \n",
    "2. **Reward Model as a Judge**: Nemotron-4 340B Reward will be used to score the 2 responses per question to be used for further alignment training via [NeMo Aligner](https://github.com/NVIDIA/NeMo-Aligner)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build.nvidia.com API Key Set-up!\n",
    "\n",
    "In order to access the endpoints through [build.nvidia.com](https://build.nvidia.com/explore/discover), an API key is required. \n",
    "\n",
    "A trial API key is made available with 1,000 tokens (or 5,000 tokens for corporate emails) - the example below will leverage ~4,500 tokens of data, but can be extended beyond that limit using local instances of the models.\n",
    "\n",
    "There are two steps to get a trial API key:\n",
    "\n",
    "1. Login (or sign up) through [build.nvidia.com](https://build.nvidia.com/)\n",
    "2. Click the `Get API Key` button available on the the `meta/llama3.1-405b-instruct` page, found [here](https://build.nvidia.com/meta/llama3.1-405b-instruct).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Subtopics, questions, and responses with Meta's Llama 3.1 405B Instruct\n",
    "\n",
    "The first part of the notebook will cover the creation of raw synthetic data from Meta's Llama 3.1 405B Instruct model.\n",
    "\n",
    "The data generated with this model can be used in accordance with [Meta's Llama 3.1 License]()\n",
    "\n",
    "### NEED LICENSE LINK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates for Synthetic Data Generation\n",
    "\n",
    "To generate questions and responses, there are a few prompt templates required:\n",
    "\n",
    "1. A prompt template to generate subtopics from a user provided topic\n",
    "2. A prompt template to generate questions for a given subtopic\n",
    "2. A prompt template to generate responses for a given question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_GENERATION_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Given a topic, generate a list of {n_subtopics} subtopics that are related to the topic.\n",
    "\n",
    "The topic is: {topic}\n",
    "\n",
    "The list must be without numbers, and without any description of the subtopics. The subtopics should be separated by a comma. There must be no other text than the list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Given a topic, generate {n_questions} questions that could be asked about that topic. Your response should be in a list format.\n",
    "\n",
    "The topic is: {sub_topic}\n",
    "\n",
    "The list must be without numbers. The questions should be separated by a newline character. There must be no other text than the list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Given a question, generate 2 responses that could be given to that question. Your response should be in a list format.\n",
    "\n",
    "The question is: {question}\n",
    "\n",
    "The list must be in the format:\n",
    "\n",
    "RESPONSE A: Response A text here\n",
    "RESPONSE B: Response B text here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined below are the parameters that will be used throughout the notebook to generate numbers of datapoints. \n",
    "\n",
    "1. `n_subtopics`, for the given topic `10` sub-topics will be generated by Meta's Llama 3.1 405B Instruct\n",
    "2. `n_questions`, for the given sub-topic, `10` questions will be generated by Llama 3.1 405B Instruct\n",
    "\n",
    "> NOTE: Using the default parameters above - there will be 10 sub-topics, each with 10 questions, each with 2 (hardcoded) responses. That is a total of an estimated ~200 rows of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subtopics = 10\n",
    "n_questions = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting OpenAI Client for Synthetic Data Generation\n",
    "\n",
    "Due to [build.nvidia.com](https://build.nvidia.com/)'s integration with the OpenAI API template - the OpenAI Python library can be used to interact with Meta's Llama 3.1 405B Instruct and Nemotron-4 340B Reward.\n",
    "\n",
    "To begin, install the [OpenAI Python library](https://github.com/openai/openai-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the NVIDIA API key obtained above in order to ensure access to both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Please enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the OpenAI Async client will enable quick and efficient data generation.\n",
    "\n",
    "It's as easy as pointing the `base_url` parameter to `https://integrate.api.nvidia.com/v1` - and providing the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = os.environ[\"NVIDIA_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Subtopics\n",
    "\n",
    "To start things off, subtopics will be generated for the provided topic. \n",
    "\n",
    "> NOTE: The parameters of `temperature`, `top_p`, and `max_tokens` can be customized to individual preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_subtopics(client, topic, n_subtopics):\n",
    "    prompt = TOPIC_GENERATION_PROMPT_TEMPLATE.format(topic=topic, n_subtopics=n_subtopics)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"meta/llama3.1-405b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main topic can be defined below - for the example in the notebook, \"Machine Learning\" will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Machine Learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will call the Meta's Llama 3.1 405B Instruct endpoint - and return a list of subtopics separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = await generate_subtopics(client, topic=topic, n_subtopics=n_subtopics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output conforms to the expected format below.\n",
    "\n",
    "> NOTE: It is possible that additional data cleaning, or formatting may be necessary depending on the prompt templates used. Be sure to confirm the format of the generated data at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning, Natural Language Processing, Computer Vision, Predictive Modeling, Clustering Algorithms, Neural Networks, Regression Analysis\n"
     ]
    }
   ],
   "source": [
    "print(responses.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the data being generated in a comma separated list, Python's `.split(\",\")` will convert the string into a usable list for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtopic_list = responses.choices[0].message.content.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Questions from Subtopic List\n",
    "\n",
    "With a list of subtopics, the next step will be to generate `n_questions`, for each subtopic.\n",
    "\n",
    "First, there needs to be a function to generate \"batches\" of questions.\n",
    "\n",
    "> NOTE: It would suitable to generate a single question per topic at a time, but more care would be needed to confirm there were no duplicate questions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_questions(client, sub_topic, n_questions):\n",
    "    prompt = QUESTION_PROMPT_TEMPLATE.format(sub_topic=sub_topic, n_questions=n_questions)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"stg/meta/llama3.1-405b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step leverages [`asyncio`](https://docs.python.org/3/library/asyncio.html) from Python's standard library for efficient API calls to [build.nvidia.com](https://build.nvidia.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def question_generator(client, subtopic_list, n_question):\n",
    "    tasks = [generate_questions(client, subtopic, n_question) for subtopic in subtopic_list]\n",
    "    question_list = await asyncio.gather(*tasks)\n",
    "    return question_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to running in a notebook environment - it is necessary to use `nest_asyncio` to run an event loop during the current Jupyter event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "question_list = asyncio.run(question_generator(client, subtopic_list, n_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to examine the output of the above process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is supervised learning and how does it differ from unsupervised learning?\\n\\nHow does supervised learning work in the context of machine learning algorithms?\\n\\nWhat are the advantages and disadvantages of using supervised learning in real-world applications?\\n\\nCan supervised learning be used for both classification and regression problems?\\n\\nWhat is the role of labeled data in supervised learning and how is it used to train models?\\n\\nHow do supervised learning algorithms handle noisy or missing data in the training set?\\n\\nWhat are some common supervised learning algorithms and how do they compare to each other?\\n\\nHow does overfitting occur in supervised learning and what techniques can be used to prevent it?\\n\\nWhat is the difference between supervised learning and reinforcement learning?\\n\\nCan supervised learning be used for time-series forecasting and if so, how does it work?',\n",
       " 'What is the primary goal of unsupervised learning, and how does it differ from supervised learning?\\n\\nHow do clustering algorithms, such as k-means and hierarchical clustering, group similar data points together?\\n\\nWhat is dimensionality reduction, and how is it used in unsupervised learning to simplify complex data sets?\\n\\nCan you explain the concept of anomaly detection, and how is it used to identify outliers in a data set?\\n\\nWhat is the difference between a generative model and a discriminative model in unsupervised learning?\\n\\nHow does the DBSCAN algorithm handle varying densities and noise in a data set?\\n\\nWhat is the role of feature extraction in unsupervised learning, and how does it relate to feature selection?\\n\\nHow do autoencoders and Generative Adversarial Networks (GANs) learn to represent complex data distributions?\\n\\nWhat are some common evaluation metrics for unsupervised learning models, and how are they used to assess performance?\\n\\nCan you describe a scenario where unsupervised learning would be more suitable than supervised learning for solving a particular problem?',\n",
       " 'What is the main goal of reinforcement learning in artificial intelligence?\\n\\nHow does reinforcement learning differ from supervised and unsupervised learning?\\n\\nWhat is the role of an agent in a reinforcement learning system?\\n\\nCan reinforcement learning be used in situations where the environment is partially observable?\\n\\nWhat is the concept of exploration-exploitation trade-off in reinforcement learning?\\n\\nHow do reinforcement learning algorithms handle delayed rewards or sparse rewards?\\n\\nWhat is the difference between on-policy and off-policy reinforcement learning?\\n\\nCan reinforcement learning be applied to real-world problems such as robotics and autonomous vehicles?\\n\\nHow does reinforcement learning relate to game theory and multi-agent systems?\\n\\nWhat are some of the challenges and limitations of reinforcement learning in complex environments?',\n",
       " 'What is the fundamental difference between deep learning and traditional machine learning approaches?\\n\\nHow do deep neural networks handle complex data such as images, speech, and text?\\n\\nWhat is the role of activation functions in deep learning models?\\n\\nCan deep learning models be used for both supervised and unsupervised learning tasks?\\n\\nHow do convolutional neural networks (CNNs) and recurrent neural networks (RNNs) differ in their applications?\\n\\nWhat is the concept of overfitting in deep learning, and how can it be addressed?\\n\\nHow do deep learning models learn to represent and generalize from large datasets?\\n\\nWhat is the significance of batch normalization and dropout techniques in deep learning?\\n\\nCan deep learning models be interpreted and explained, or are they black boxes?\\n\\nHow do deep learning frameworks such as TensorFlow and PyTorch support the development of deep learning models?',\n",
       " 'What are the main applications of Natural Language Processing in real-world scenarios?\\n\\nHow does Natural Language Processing differ from traditional computer programming languages?\\n\\nWhat are the key challenges in developing Natural Language Processing systems that can understand nuances of human language?\\n\\nCan Natural Language Processing systems truly \"understand\" the meaning of text, or are they limited to pattern recognition?\\n\\nWhat role does machine learning play in the development of Natural Language Processing systems?\\n\\nHow do Natural Language Processing systems handle ambiguity and uncertainty in language?\\n\\nWhat are some common techniques used in Natural Language Processing for text preprocessing and normalization?\\n\\nHow can Natural Language Processing be used to improve human-computer interaction and user experience?\\n\\nWhat are some potential biases and limitations of Natural Language Processing systems, and how can they be addressed?\\n\\nCan Natural Language Processing systems be used to generate creative content, such as stories or poetry, that is indistinguishable from human-generated content?',\n",
       " 'What are the primary applications of computer vision in the field of robotics?\\n\\nHow does computer vision differ from image processing, and what are the key overlaps between the two?\\n\\nWhat role does machine learning play in the development of computer vision systems?\\n\\nCan computer vision systems be used to accurately recognize and classify objects in real-time?\\n\\nWhat are some of the most significant challenges in developing computer vision systems for autonomous vehicles?\\n\\nHow does computer vision contribute to the field of augmented reality?\\n\\nWhat are the key differences between structured and unstructured computer vision approaches?\\n\\nCan computer vision systems be used to detect and analyze human emotions and behavior?\\n\\nWhat are some potential security risks associated with the use of computer vision systems?\\n\\nHow does computer vision intersect with other areas of artificial intelligence, such as natural language processing?',\n",
       " \"What is predictive modeling and how is it used in real-world applications?\\n\\nHow does predictive modeling differ from descriptive and prescriptive analytics?\\n\\nWhat are some common techniques used in predictive modeling, such as regression and decision trees?\\n\\nWhat is the role of data quality and preprocessing in building accurate predictive models?\\n\\nHow do predictive models handle missing or incomplete data?\\n\\nWhat is overfitting in predictive modeling, and how can it be prevented?\\n\\nHow do ensemble methods, such as bagging and boosting, improve predictive model performance?\\n\\nWhat is the difference between a predictive model's accuracy and its interpretability?\\n\\nHow can predictive models be validated and evaluated for their performance?\\n\\nCan predictive models be used for both classification and regression tasks, and how do the approaches differ?\",\n",
       " 'What are the most common types of clustering algorithms used in data analysis?\\n\\nHow do clustering algorithms handle outliers and noisy data in a dataset?\\n\\nCan clustering algorithms be used for both supervised and unsupervised learning tasks?\\n\\nWhat is the difference between hierarchical and non-hierarchical clustering algorithms?\\n\\nHow do clustering algorithms determine the optimal number of clusters in a dataset?\\n\\nWhat is the role of distance metrics in clustering algorithms, and how do they affect the results?\\n\\nHow do clustering algorithms handle high-dimensional data, and what are the challenges associated with it?\\n\\nCan clustering algorithms be used for real-time data analysis, and what are the limitations?\\n\\nHow do clustering algorithms handle overlapping or fuzzy clusters in a dataset?\\n\\nWhat are some common evaluation metrics used to assess the performance of clustering algorithms?',\n",
       " 'What is the basic structure of a neural network and how do its components interact?\\n\\nHow do neural networks learn from data, and what is the role of backpropagation in this process?\\n\\nWhat are the differences between supervised, unsupervised, and reinforcement learning in neural networks?\\n\\nCan neural networks be used for tasks other than classification and regression, such as clustering or dimensionality reduction?\\n\\nHow do convolutional neural networks (CNNs) and recurrent neural networks (RNNs) differ from traditional feedforward networks?\\n\\nWhat is the vanishing gradient problem in neural networks, and how can it be addressed?\\n\\nHow do neural networks handle missing or noisy data, and what techniques can be used to improve their robustness?\\n\\nWhat is the role of activation functions in neural networks, and how do different activation functions affect network behavior?\\n\\nCan neural networks be used for real-time processing and decision-making, or are they limited to batch processing?\\n\\nHow can neural networks be interpreted and explained, and what techniques are available for understanding their decisions and behavior?',\n",
       " 'What is the primary purpose of regression analysis in statistics?\\n\\nHow does simple linear regression differ from multiple linear regression?\\n\\nWhat are the assumptions that must be met for a regression analysis to be considered valid?\\n\\nWhat is the difference between a dependent variable and an independent variable in regression analysis?\\n\\nHow is the coefficient of determination (R-squared) used to evaluate the fit of a regression model?\\n\\nWhat is the purpose of residual analysis in regression, and how is it performed?\\n\\nHow does multicollinearity affect the results of a regression analysis, and how can it be addressed?\\n\\nWhat is the difference between a linear regression model and a nonlinear regression model?\\n\\nHow is regression analysis used in forecasting and prediction, and what are some common applications?\\n\\nWhat are some common pitfalls or limitations of regression analysis that researchers should be aware of?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list for each question is now collected into a single long list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list_formatted = []\n",
    "\n",
    "for question_set in question_list:\n",
    "    question_list_formatted += question_set.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_list_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Responses from Question List\n",
    "\n",
    "Using the question list, Meta's Llama 3.1 405B Instruct can be used to generate responses to the questions. \n",
    "\n",
    "The first things needed is a function that will be used to generate the response from [build.nvidia.com](https://build.nvidia.com/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_responses(client, question):\n",
    "    prompt = RESPONSE_PROMPT_TEMPLATE.format(question=question)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"stg/meta/llama3.1-405b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the `asycio` library allows efficient use of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def response_generator(client, question_list):\n",
    "    tasks = [generate_responses(client, question) for question in question_list]\n",
    "    response_list = await asyncio.gather(*tasks)\n",
    "    return response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response_list = asyncio.run(response_generator(client, question_list_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are two possible responses to the question:\\n\\nRESPONSE A: Supervised learning is a type of machine learning where the algorithm is trained on labeled data, meaning the data is already tagged with the correct output. The goal of supervised learning is to learn a mapping between input data and the corresponding output labels, so the algorithm can make predictions on new, unseen data. In contrast, unsupervised learning involves training an algorithm on unlabeled data, and the goal is to identify patterns or structure in the data without any prior knowledge of the output labels.\\n\\nRESPONSE B: Supervised learning is a machine learning approach where the model is trained on a dataset that includes both input data and corresponding output labels. This allows the model to learn from the labeled examples and make predictions on new data. Unsupervised learning, on the other hand, involves training a model on a dataset without any output labels, and the goal is to discover hidden patterns or relationships in the data. The key difference between the two is that supervised learning is focused on making predictions based on labeled data, while unsupervised learning is focused on discovering new insights and patterns in the data without any prior knowledge of the output labels.',\n",
       " 'Here are two possible responses to the question:\\n\\nRESPONSE A: Supervised learning is a type of machine learning algorithm where the model is trained on labeled data, meaning the data is already tagged with the correct output. The model learns to map inputs to outputs based on the labeled data, and its performance is evaluated on a separate test dataset. The goal of supervised learning is to make predictions on new, unseen data by generalizing the patterns learned from the training data. For example, a supervised learning model can be trained on images of dogs and cats, labeled as such, to learn to classify new images as either dogs or cats.\\n\\nRESPONSE B: Supervised learning works by using a dataset that contains input-output pairs, where the input is the data and the output is the corresponding label or response. The machine learning algorithm learns to identify the relationship between the input data and the output labels, and uses this knowledge to make predictions on new data. The process involves three main steps: data preparation, model training, and model evaluation. During training, the model is presented with the labeled data and adjusts its parameters to minimize the error between its predictions and the actual labels. Once the model is trained, it can be used to make predictions on new data, and its performance is evaluated using metrics such as accuracy, precision, and recall.',\n",
       " 'Here are two possible responses to the question:\\n\\nRESPONSE A: Supervised learning has several advantages, including high accuracy and efficiency in solving well-defined problems, ease of implementation, and interpretability of results. However, its main disadvantage is that it requires a large amount of labeled data, which can be time-consuming and expensive to obtain. Additionally, supervised learning models can be prone to overfitting and may not generalize well to new, unseen data. In real-world applications, supervised learning is suitable for tasks such as image classification, sentiment analysis, and speech recognition, where high accuracy is crucial and the data is well-structured.\\n\\nRESPONSE B: The advantages of supervised learning in real-world applications include its ability to learn from data and improve over time, its robustness to noise and outliers, and its ability to handle complex, high-dimensional data. However, supervised learning also has some significant disadvantages, including the need for large amounts of labeled data, the risk of model bias and overfitting, and the difficulty of selecting the right features and hyperparameters. In addition, supervised learning models can be computationally expensive to train and deploy, and may require significant expertise to interpret and maintain. Despite these challenges, supervised learning remains a widely used and effective approach in many applications, including natural language processing, recommender systems, and predictive maintenance.',\n",
       " 'Here are 2 possible responses to the question:\\n\\nRESPONSE A: Yes, supervised learning can be used for both classification and regression problems. In classification, the goal is to predict a categorical label, while in regression, the goal is to predict a continuous value. Supervised learning algorithms such as decision trees, random forests, and support vector machines can be used for both classification and regression tasks, with the main difference being the type of output variable.\\n\\nRESPONSE B: Absolutely, supervised learning is a versatile machine learning approach that can be applied to both classification and regression problems. For classification problems, supervised learning algorithms learn to map inputs to discrete labels, while for regression problems, they learn to map inputs to continuous outputs. Many popular supervised learning algorithms, including linear regression, logistic regression, and neural networks, can be adapted for use in either classification or regression settings, making supervised learning a powerful tool for a wide range of applications.',\n",
       " \"Here are two possible responses to the question:\\n\\nRESPONSE A: Labeled data plays a crucial role in supervised learning as it provides the model with a clear understanding of the relationship between input data and the corresponding output. The labeled data is used to train the model, where the model learns to map the input data to the correct output based on the labels provided. The model uses this labeled data to adjust its parameters and minimize the error between its predictions and the actual labels, ultimately improving its performance and accuracy.\\n\\nRESPONSE B: In supervised learning, labeled data serves as a guide for the model to learn from, allowing it to make predictions on new, unseen data. The labeled data is used to train the model through a process of pattern recognition, where the model identifies relationships between the input data and the corresponding labels. As the model is trained on the labeled data, it becomes increasingly accurate in its predictions, and the labeled data helps to refine the model's performance by providing a benchmark against which to measure its accuracy.\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_response_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to move to the next stage, a dataset will be created in `.jsonl` format and will store questions with the responses generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response_pair_list = []\n",
    "for question, response_set in zip(question_list_formatted, question_response_list):\n",
    "    question_response_pair_list.append(\n",
    "        {\n",
    "            \"question\" : question, \n",
    "            \"responses\" : {\n",
    "                \"response_a\" : {\"response\" : response_set.split(\"RESPONSE B:\")[0].replace(\"RESPONSE A:\", \"\").strip().split(\"\\n\\n\")[-1].strip()},\n",
    "                \"response_b\" : {\"response\" : response_set.split(\"RESPONSE B:\")[-1].split(\"\\n\\n\")[0].strip()}\n",
    "            },\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset will be written out to a file called `synthetic_data.jsonl` below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('synthetic_data.jsonl', 'w') as f:\n",
    "    for item in question_response_pair_list:\n",
    "        f.write(json.dumps(item))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Nemotron-4 340B Reward to Generate a Preference Dataset\n",
    "\n",
    "Equipped with a dataset that has questions that have response pairs, a preference dataset that is compatible with DPO training, SteerLM reward model training, and RLHF reward model training can be generated straightforwardly thanks to [Nemotron-4 340B Reward](https://build.nvidia.com/nvidia/nemotron-4-340b-reward) available through [build.nvidia.com](https://build.nvidia.com/)!\n",
    "\n",
    "First, an example of how to use the endpoint.\n",
    "\n",
    "1. You must both provide a user message, and an assistant message!\n",
    "2. It will return a chat-style message with the scores, as well as the scores in the `logprogs` parameter.\n",
    "\n",
    "The response package will include scores related to five attributes:\n",
    "\n",
    "1. Helpfulness: Overall helpfulness of the response to the prompt.\n",
    "2. Correctness: Inclusion of all pertinent facts without errors.\n",
    "3. Coherence: Consistency and clarity of expression.\n",
    "4. Complexity: Intellectual depth required to write response (i.e. whether the response can be written by anyone with basic language competency or requires deep domain expertise).\n",
    "5. Verbosity: Amount of detail included in the response, relative to what is asked for in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : \"Hello!\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hello! How can I help you today?\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await client.chat.completions.create(\n",
    "        model=\"nvidia/nemotron-4-340b-reward\",\n",
    "        messages=messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='426fb23a-176b-4553-a80c-9d53b130b6fb', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=4.09375, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=4.03125, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=4.25, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.5703125, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.109375, top_logprobs=[])]), message=[ChatCompletionMessage(content='helpfulness:4.09375,correctness:4.03125,coherence:4.25,complexity:0.5703125,verbosity:1.109375', role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=54, total_tokens=55))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `logprobs` can be handled in a similar fashion to message content, as demonstrated below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=4.09375, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=4.03125, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=4.25, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.5703125, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.109375, top_logprobs=[])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].logprobs.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to define a simple helper function that can extract the scores to be used in the construction of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_from_response(openai_response_template):\n",
    "    logprobs = openai_response_template.choices[0].logprobs.content\n",
    "    score_dict = {}\n",
    "    for score in logprobs:\n",
    "        score_dict[score.token] = score.logprob\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'helpfulness': 4.09375,\n",
       " 'correctness': 4.03125,\n",
       " 'coherence': 4.25,\n",
       " 'complexity': 0.5703125,\n",
       " 'verbosity': 1.109375}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores_from_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the synthetic data generation above, using `asyncio` will help provide scores in a time-efficient manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_response_and_scores(client, model, question, response_content):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response_content\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    scores = get_scores_from_response(response)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the list is important to avoid overwriting or modifying the original data - though it can be reloaded from `JSONL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response_score_list = question_response_pair_list.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores are calculated efficiently using `asyncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_question_response_pairs(client, model, question_response_score_list):\n",
    "    tasks = []\n",
    "    for question_response_pair in question_response_score_list:\n",
    "        question = question_response_pair[\"question\"]\n",
    "        \n",
    "        task_a = get_response_and_scores(client, model, question, question_response_pair[\"responses\"][\"response_a\"][\"response\"])\n",
    "        task_b = get_response_and_scores(client, model, question, question_response_pair[\"responses\"][\"response_b\"][\"response\"])\n",
    "        \n",
    "        tasks.append((task_a, question_response_pair, \"response_a\"))\n",
    "        tasks.append((task_b, question_response_pair, \"response_b\"))\n",
    "    \n",
    "    results = await asyncio.gather(*[task[0] for task in tasks])\n",
    "    \n",
    "    for i, (result, task_info) in enumerate(zip(results, tasks)):\n",
    "        _, question_response_pair, response_key = task_info\n",
    "        question_response_pair[\"responses\"][response_key].update(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing left to do but fire it off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_question_response_pairs(client, \"nvidia/nemotron-4-340b-reward\", question_response_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality can be relatively preserved by only keeping rows that have at least a `3.0` in the overall metric - in this case helpfulness. This will help ensure that the data remains high quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FInally, the dataset can be exported in `.JSONL` format for use in [NeMo Aligner](https://github.com/NVIDIA/NeMo-Aligner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'synthetic_data_with_scores_filtered-{threshold}.jsonl', 'w') as f:\n",
    "    for item in question_response_score_list:\n",
    "        question = item[\"question\"]\n",
    "        response_a = item[\"responses\"][\"response_a\"]\n",
    "        response_b = item[\"responses\"][\"response_b\"]\n",
    "        response_a[\"question\"] = question\n",
    "        response_b[\"question\"] = question\n",
    "        if response_a[\"helpfulness\"] < threshold and response_b[\"helpfulness\"] < threshold:\n",
    "            continue\n",
    "        f.write(json.dumps(response_a))\n",
    "        f.write('\\n')\n",
    "        f.write(json.dumps(response_b))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
